x-strobes-image: &strobes-image docker.strobes.co/strobes-api:v2.5.158
x-strobes-depends-on: &strobes-depends-on
  - rabbitmq
  - postgres
x-strobes-volumes: &strobes-volumes
    - media_data:/usr/src/app/media/
    - triangulum_artifacts:/artifacts/


version: '3.4'
services:

  frontend:
    image: docker.strobes.co/strobes-fe-v2:v1.3.70
    command: bash -c 'serve -s build -l 3000'
    expose:
      - 3000
    restart: always

  nginx:
    build:
      context: .
      dockerfile: ./nginx/Dockerfile
    ports:
      - 80:80
    depends_on:
      - api
      - frontend

  api:
    image: *strobes-image
    command: sh scripts/start_api.sh
    expose:
      - 8000
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    env_file:
      - ./api.env
    environment:
      - CONTAINER=web
    restart: always

  celery_beat:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_beat
    restart: always

  celery_short_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 8G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_short_task_worker
    restart: always

  celery_long_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 8G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_long_task_worker
    restart: always

  celery_very_short_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 8G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_very_short_task_worker
    restart: always

  celery_cve_request_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_cve_request_task_worker
    restart: always

  celery_priority_request_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_priority_request_task_worker
    restart: always

  celery_onboarding_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_onboarding_task_worker
    restart: always

  celery_parser_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 8G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_parser_task_worker
    restart: always

  celery_notification_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_notification_task_worker
    restart: always

  celery_dashboard_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_dashboard_task_worker
    restart: always

  celery_tracker_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_tracker_task_worker
    restart: always

  celery_export_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 4G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_export_task_worker
    restart: always


  celery_bulk_actions_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 4G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_bulk_actions_worker
    restart: always


  postgres:
    image: postgres:11.10-alpine
    expose:
      - 5432
    command: postgres -c max_connections=1200 -c shared_buffers=5GB -c effective_cache_size=30GB -c maintenance_work_mem=1280MB -c checkpoint_completion_target=0.9 -c wal_buffers=16MB -c default_statistics_target=100 -c random_page_cost=1.1 -c effective_io_concurrency=200 -c work_mem=256MB -c min_wal_size=2GB -c max_wal_size=8GB -c max_worker_processes=4 -c max_parallel_workers_per_gather=4 -c max_parallel_workers=8 -c max_parallel_maintenance_workers=2
    env_file:
      - ./api.env
    volumes:
      - postgresql_data:/var/lib/postgresql/data
    restart: always

  rabbitmq:
    image: rabbitmq:3.8.3-alpine
    labels:
      NAME: rabbitmq
    volumes:
      - ./rabbitmq_config/:/etc/rabbitmq/
      - rabbitmq_data:/var/lib/rabbitmq
    expose:
      - 5672
    restart: always

  fluentbit:
    image: fluent/fluent-bit:1.5
    volumes:
      - ./fluent-bit/conf:/fluent-bit/etc
    expose:
      - 24224
    restart: always

  elasticsearch:
    image: elasticsearch:7.7.0
    ports:
      - 9200:9200
    volumes:
      - esdata:/usr/share/elasticsearch/data
    environment:
      - discovery.type=single-node
    restart: always
  
  cache:
    image: redis:6.2-alpine
    restart: always
    ports:
      - '6379:6379'
    command: redis-server --maxmemory 11145728000 --maxmemory-policy allkeys-lru
    deploy:
      resources:
        limits:
          memory: 12G
    volumes:
      - cache:/data
  
  pgbouncer:
    image: edoburu/pgbouncer
    env_file:
     - ./api.env
    volumes:
     - ./pgbouncer/pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini
    restart: always

volumes:
  postgresql_data:
    driver: local
  rabbitmq_data:
    driver: local
  esdata:
    driver: local
  media_data:
    driver: local
  triangulum_artifacts:
    name: triangulum_output
    driver: local
  cache:
    driver: local
