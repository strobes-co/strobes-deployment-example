x-strobes-image: &strobes-image docker.strobes.co/strobes-api:v3.90.0
x-strobes-depends-on: &strobes-depends-on
  - rabbitmq
  - postgres
x-strobes-volumes: &strobes-volumes
    - media_data:/usr/src/app/media/
    - triangulum_artifacts:/artifacts/
    - triangulum_output:/output/

version: '3.4'
services:
  frontend:
    image: docker.strobes.co/strobes-fe-v2:v3.82.6
    command: ["nginx", "-g", "daemon off;"]
    expose:
      - 3000
    restart: always

  nginx:
    build:
      context: .
      dockerfile: ./nginx/Dockerfile
    ports:
      - 80:80
    depends_on:
      - api
      - frontend

  api:
    image: *strobes-image
    command: sh scripts/start_api.sh
    expose:
      - 8000
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    env_file:
      - ./api.env
    environment:
      - CONTAINER=web
    restart: always

  celery_beat:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_beat
    restart: always

  celery_short_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 4G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_short_task_worker
    restart: always

  celery_long_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 4G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_long_task_worker
    restart: always

  celery_very_short_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 4G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_very_short_task_worker
    restart: always

  celery_cve_request_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_cve_request_task_worker
    restart: always

  celery_priority_request_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_priority_request_task_worker
    restart: always

  celery_parser_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 4G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_parser_task_worker
    restart: always

  celery_notification_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_notification_task_worker
    restart: always

  celery_status_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_status_task_worker
    restart: always

  celery_ticketing_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_ticketing_task_worker
    restart: always

  celery_alert_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 512M
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_alert_task_worker
    restart: always

  celery_export_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 4G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_export_task_worker
    restart: always

  celery_system_bulk_actions_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 4G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_system_bulk_actions_worker
    restart: always
  
  celery_user_bulk_actions_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 2G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_user_bulk_actions_worker
    restart: always
  
  celery_listener_task_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 1G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_listener_task_worker
    restart: always

  celery_automation_action_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 2G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_automation_action_worker
    restart: always

  celery_automation_trigger_worker:
    image: *strobes-image
    command: bash scripts/start_celery.sh
    volumes: *strobes-volumes
    depends_on: *strobes-depends-on
    deploy:
        resources:
            limits:
              memory: 2G
    env_file:
      - ./api.env
    environment:
      - CONTAINER=celery_automation_trigger_worker
    restart: always

  postgres:
    image: postgres:11.10-alpine
    expose:
      - 5432
    command: postgres -c max_connections=1200 -c shared_buffers=4GB -c effective_cache_size=12GB -c maintenance_work_mem=1GB -c checkpoint_completion_target=0.9 -c wal_buffers=16MB -c default_statistics_target=100 -c random_page_cost=1.1 -c effective_io_concurrency=200 -c work_mem=1747kB -c min_wal_size=1GB -c max_wal_size=4GB -c max_worker_processes=4 -c max_parallel_workers_per_gather=2 -c max_parallel_workers=4 -c max_parallel_maintenance_workers=2
    env_file:
      - ./api.env
    volumes:
      - postgresql_data:/var/lib/postgresql/data
      - ./configs/init-extensions.sql:/docker-entrypoint-initdb.d/init-extensions.sql
    restart: always

  rabbitmq:
    image: rabbitmq:3.8.3-alpine
    labels:
      NAME: rabbitmq
    volumes:
      - ./rabbitmq_config/:/etc/rabbitmq/
      - rabbitmq_data:/var/lib/rabbitmq
    expose:
      - 5672
    restart: always

  fluentbit:
    image: fluent/fluent-bit:1.5
    volumes:
      - ./fluent-bit/conf:/fluent-bit/etc
    expose:
      - 24224
    restart: always

  elasticsearch:
    image: elasticsearch:7.7.0
    ports:
      - 9200:9200
    volumes:
      - esdata:/usr/share/elasticsearch/data
    environment:
      - discovery.type=single-node
    restart: always
  
  cache:
    image: redis:6.2-alpine
    restart: always
    ports:
      - '6379:6379'
    command: redis-server --maxmemory 11145728000 --maxmemory-policy allkeys-lru
    deploy:
      resources:
        limits:
          memory: 12G
    volumes:
      - cache:/data
  
  pgbouncer:
    image: edoburu/pgbouncer
    env_file:
     - ./pgbouncer.env
    volumes:
     - ./pgbouncer/pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini
    restart: always

  triangulum:
    image: docker.strobes.co/triangulum:v5.1.1
    hostname: "triangulum"
    expose:
      - 50051
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - triangulum_output:/output/
      - triangulum_artifacts:/artifacts/
    depends_on:
      - rabbitmq
    env_file:
      - ./triangulum.env
    restart: always

  rabbitmq_tri:
    image: rabbitmq:3.8-management
    labels:
      NAME: rabbitmq_tri
    volumes:
      - ./rabbitmq_config/:/etc/rabbitmq/
      - rabbitmq_tri_data:/var/lib/rabbitmq
    expose:
      - 5672
    restart: always

volumes:
  postgresql_data:
    driver: local
  rabbitmq_data:
    driver: local
  esdata:
    driver: local
  media_data:
    driver: local
  triangulum_artifacts:
    name: triangulum_artificats
    driver: local
  cache:
    driver: local
  triangulum_output:
    name: triangulum_output
    driver: local
  rabbitmq_tri_data:
    driver: local
